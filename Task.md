1.4.1. Task 1: Working with the documents (for all tasks the case when a resume is bigger than the model tokens window has to be handled):
Translation. Find the resumes (or parts of them) that are not in English, and translate them into English using LLM.
Entities extraction. Extract useful named entities from the resume using LLM. For example, you can extract the job title, years of experience, highest level of education, language skills, and key skills, or define any entities that you find interesting. As an additional task, you may create an Excel report that contains entities from 20-30 resumes.
Summarisation. Make a short summary of the resume. You may choose any size you find useful. Defining the structure of the summary (adding the obligatory entities) or just getting it from LLM is up to you. The general idea is to provide an opportunity for recruiters to read it quickly and not scan 2-3 pages.
Resume scoring. Develop a mechanism to provide a ranking of the resumes for a vacancy by providing a score (float value from 0 to 1). A particular vacancy can be found at https://www.dataart.team/vacancies (or on LinkedIn). It should work into one match (how the one resume fits the vacancy) and present the top 10 candidates for the vacancy. (Do not do an outdated version if you start the course after 11.12.2023. Outdated version: Text modification/tuning. Choose any job title (Accountant, Project Manager, Sales, HR, Designer, etc.) that exists in the dataset. Modify the text of the picked resume to fit better for a particular vacancy from https://www.dataart.team/vacancies (or from LinkedIn).)
NOTE: If you have chosen the Generative AI path for your learning, the competency is expecting that you finish the Task 1 practice 3 weeks after the beginning of the course.

1.4.2. Task 2: Working with Vector Database:
Knowledge Base Organisation. Create a script to clean, split to chucks, and get embedding from the resume (Langchain might help there). Store the results with useful metadata in a local Vector Database like Qdrant, Chroma, or others.
Answers are based on the database. Using the results of the search in the database is a context for LLM to answer questions about data. Question examples: How many Senior Python Engineers are in a database? Who is the most qualified accountant? And etc.
NOTE: If you have chosen the Generative AI path for your learning, the competency is expecting that you finish the Task 2 practice 4-5 weeks after the beginning of the course.